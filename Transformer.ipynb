{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')\n",
    "import scipy.optimize as opt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "import keras\n",
    "import pandas as pd\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sys\n",
    "from keras import metrics\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "    \n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "    to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "    \n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "    \n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900000, 32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The shape of input data like (Number of data, x-axis, y-axis)\n",
    "## The meaning of data sets (Number of data, sentens, words)\n",
    "rinv = \"0p3\"\n",
    "file_path = \"pre_LL_\"+rinv+\".h5\"\n",
    "hdf_file = '/local_disk2/james/Taylor_data/semi-visible-jets-ml/data/LL/LL-0p3.h5'\n",
    "hf = h5py.File(hdf_file, \"r\")\n",
    "X = hf[\"features\"][:]\n",
    "Y = hf[\"targets\"][:]\n",
    "X.shape # (number of jet images, x-axis, y-axis )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X)\n",
    "Ntrain, Nval, Ntest = int(N/5*4),  int(N/10),  int(N/10)\n",
    "Xim_train, Xim_val, Xim_test = X[:Ntrain], X[Ntrain:Nval+Ntrain], X[Nval+Ntrain:N]\n",
    "yim_train, yim_val, yim_test = Y[:Ntrain], Y[Ntrain:Nval+Ntrain], Y[Nval+Ntrain:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 32)\n",
      "att\n",
      "(None, None, 32)\n",
      "att\n",
      "(None, None, 32)\n",
      "(None, 32, 32)\n",
      "(None, 32, 32)\n",
      "(None, 32, 32)\n",
      "(None, 32, 32)\n",
      "(None, None, 32)\n",
      "(None, None, 32)\n",
      "(None, 32, 32)\n",
      "(None, None, 32)\n",
      "(None, None, 32)\n",
      "(None, 32, 32)\n",
      "(None, 32, 32)\n",
      "(None, 32, 32)\n",
      "(None, 32, 32)\n",
      "(None, 1024)\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "d_mode = X.shape[-1]\n",
    "dff = 2048\n",
    "num_heads =  X.shape[-1]\n",
    "dprate = 0.1\n",
    "R = 1.65\n",
    "inputs = tf.keras.Input(shape=( X.shape[-2], X.shape[-1]))\n",
    "\n",
    "x = inputs\n",
    "print(x.shape)\n",
    "\n",
    "# x = x+R\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "# x = tf.expand_dims(x, axis=-1)\n",
    "# print(x.shape)\n",
    "# x = Attention()(x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = Linear()(x)\n",
    "# print(x.shape)\n",
    "\n",
    "##---------------------------------------Encode layer\n",
    "print('att')\n",
    "att, _ = MultiHeadAttention(d_mode, num_heads)(x, x, x, None)\n",
    "print(att.shape)\n",
    "\n",
    "# print('att')\n",
    "# att = point_wise_feed_forward_network(d_mode, dff)(att)\n",
    "# print(att.shape)\n",
    "\n",
    "print('att')\n",
    "att = tf.keras.layers.Dropout(dprate)(att, training=False)\n",
    "print(att.shape)\n",
    "\n",
    "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x+att)\n",
    "print(x.shape)\n",
    "\n",
    "att = point_wise_feed_forward_network(d_mode, dff)(x)\n",
    "print(att.shape)\n",
    "\n",
    "att = tf.keras.layers.Dropout(dprate)(att, training=False)\n",
    "print(att.shape)\n",
    "\n",
    "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x+att)\n",
    "print(x.shape)\n",
    "##------------------------------------------------------------------------\n",
    "\n",
    "##----------------------------------------------- Decode layer\n",
    "att, _ = MultiHeadAttention(d_mode, num_heads)(x, x, x, None)\n",
    "print(att.shape)\n",
    "att = tf.keras.layers.Dropout(dprate)(att, training=False)\n",
    "print(att.shape)\n",
    "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x+att)\n",
    "print(x.shape)\n",
    "\n",
    "att, _ = MultiHeadAttention(d_mode, num_heads)(x, x, x, None)\n",
    "print(att.shape)\n",
    "att = tf.keras.layers.Dropout(dprate)(att, training=False)\n",
    "print(att.shape)\n",
    "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x+att)\n",
    "print(x.shape)\n",
    "\n",
    "att = point_wise_feed_forward_network(d_mode, dff)(x)\n",
    "print(att.shape)\n",
    "att = tf.keras.layers.Dropout(dprate)(att, training=False)\n",
    "print(att.shape)   \n",
    "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x+att)\n",
    "print(x.shape)\n",
    "\n",
    "   \n",
    "##------------------------------------------------------------------------\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "print(x.shape)\n",
    "\n",
    "# x = tf.keras.layers.Dense(256)(x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x= tf.keras.layers.Dropout(0.2)(x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = tf.keras.layers.Dense(128)(x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x= tf.keras.layers.Dropout(0.2)(x)\n",
    "# print(x.shape)\n",
    "\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "modelTransformer = tf.keras.Model(inputs= inputs, outputs=x, name='Transformer')\n",
    "\n",
    "\n",
    "# modelTransformer = tf.keras.Model(inputs= inputs, outputs=x, name='Transformer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"Transformer\"\n",
    "save_dir = './'\n",
    "model_name = '%s_model_'% model_type +rinv \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "#                                              monitor='val_auc',\n",
    "#                                              mode='max',\n",
    "#  monitor='val_acc',\n",
    "\n",
    "# lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# progress_bar = keras.callbacks.ProgbarLogger()\n",
    "\n",
    "# csv_logger = keras.callbacks.CSVLogger(save_dir+'CNN'+rinv+'.csv')\n",
    "# csv_logger = keras.callbacks.CSVLogger(save_dir+'CNN_'+rinv+'_'+optn+'_filter.csv')\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+model_type+rinv+'.csv')\n",
    "\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "                            monitor=\"val_loss\",\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3, # 10\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead ((None, None, 32), ( 4224        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 32)     0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 32, 32)]     0           input_1[0][0]                    \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 32, 32)       64          tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 32, 32)       133152      layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32)       0           sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 32, 32)]     0           layer_normalization[0][0]        \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 32, 32)       64          tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe ((None, None, 32), ( 4224        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 32)     0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 32, 32)]     0           layer_normalization_1[0][0]      \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 32, 32)       64          tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe ((None, None, 32), ( 4224        layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 32)     0           multi_head_attention_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, 32, 32)]     0           layer_normalization_2[0][0]      \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 32, 32)       64          tf_op_layer_AddV2_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 32, 32)       133152      layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32)       0           sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_4 (TensorFlow [(None, 32, 32)]     0           layer_normalization_3[0][0]      \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 32, 32)       64          tf_op_layer_AddV2_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            1025        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 280,321\n",
      "Trainable params: 280,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelTransformer.compile(optimizer=optimizer , loss=\"binary_crossentropy\", metrics=['accuracy', metrics.AUC(name=\"auc\")])\n",
    "modelTransformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668/5938 [=======>......................] - ETA: 12:43 - loss: 0.5898 - accuracy: 0.6846 - auc: 0.7509"
     ]
    }
   ],
   "source": [
    "modelTransformer.fit(Xim_train, yim_train , validation_data=(Xim_val, yim_val), callbacks = callbacks, shuffle=True , epochs=400, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTransformer.save(\"./Transformer_\"+rinv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = modelTransformer.predict(Xim_test)[:,0]\n",
    "y_score = np.hstack(y_score)\n",
    "# test=[i[1] for i in yim_test]\n",
    "fpr , tpr , thresholds = roc_curve ( yim_test , y_score)\n",
    "roc_auc = auc(tpr,fpr )\n",
    "print(\"The area under the curves are:\")\n",
    "print(\"AUC:{0:.9f}\".format(roc_auc))\n",
    "if roc_auc<0.5:\n",
    "    a = tpr\n",
    "    tpr = fpr\n",
    "    fpr = a\n",
    "    roc_auc = 1 - roc_auc\n",
    "    print(\"AUC:{0:.9f}\".format(roc_auc))\n",
    "    \n",
    "# FalsePositiveFull, TruePositiveFull, ThresholdFull = metrics.roc_curve(y_test,Predictions)\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.plot(tpr,fpr, label='Fully supervised: AUC={0:.5f}'.format(roc_auc))\n",
    "plt.ylabel('False Positive Rate',fontsize=20)\n",
    "plt.xlabel('True Positive Rate',fontsize=20)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.legend()\n",
    "# plt.legend(bbox_to_anchor=(0.8, -0.17),ncol=2)\n",
    "\n",
    "plt.legend(prop={'size': 14})\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"./Transformer_\"+rinv+\"_roc.png\")\n",
    "\n",
    "# hf = h5py.File(\"./Keras_Tunner/PR_all_\"+rinv+\"_\"+optn+\"_filter_preprocessing.h5\", 'w')\n",
    "hf = h5py.File(\"./Transformer_\"+rinv+\".h5\", 'w')\n",
    "\n",
    "hf.create_dataset('fpr', data=fpr)\n",
    "hf.create_dataset('tpr', data=tpr)\n",
    "hf.close()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "# LOSS = pd.read_csv(save_dir+\"CNN_\"+rinv+\"_\"+optn+\"_filter.csv\")\n",
    "# LOSS = pd.read_csv(save_dir+\"CNN_all_\"+rinv+\"_\"+optn+\"_filter_preprocessing.csv\")\n",
    "LOSS = pd.read_csv(save_dir+model_type+rinv+'.csv')\n",
    "\n",
    "\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.plot(LOSS[\"loss\"], label='loss',c='blue')\n",
    "plt.plot(LOSS[\"val_loss\"], label='val_loss',c='red')\n",
    "plt.plot(LOSS[\"accuracy\"], linestyle='--', label='accuracy',c='blue')\n",
    "plt.plot(LOSS[\"val_accuracy\"], linestyle='--', label='val_accuracy',c='red')\n",
    "\n",
    "plt.plot(LOSS[\"auc\"], linestyle=':', label='auc',c='blue')\n",
    "plt.plot(LOSS[\"val_auc\"], linestyle=':', label='val_auc',c='red')\n",
    "# plt.plot([0, 1], [1, 1], '--')\n",
    "\n",
    "# plt.ylim([0.3,1])\n",
    "plt.ylabel('loss',fontsize=20)\n",
    "plt.xlabel('epoch',fontsize=20)\n",
    "# plt.legend(bbox_to_anchor=(0.8, -0.17),ncol=2)\n",
    "plt.legend(bbox_to_anchor=(0.8, -0.17),ncol=2)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"./Keras_Tunner/CNN_\"+rinv+\"_\"+optn+\"_filter_loss.png\")\n",
    "# plt.savefig(\"./Keras_Tunner/CNN_all_\"+rinv+\"_\"+optn+\"_filter_loss_preprocessing.png\")\n",
    "plt.savefig(\"./Transformer_\"+rinv+\"_loss.png\")\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
